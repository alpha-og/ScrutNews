{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/train.csv\")\n",
    "\n",
    "split = 0.8\n",
    "df = df.sample(frac=1).dropna()\n",
    "train = df[:int(0.8*df.shape[0])]\n",
    "test = df[int(0.8*df.shape[0]):]\n",
    "\n",
    "x_train, y_train = train[\"title\"], train[\"label\"]\n",
    "x_test, y_test = test[\"title\"], test[\"label\"]\n",
    "\n",
    "x_train_enc = [one_hot(words,10000) for words in x_train]\n",
    "x_test_enc = [one_hot(words,10000) for words in x_test]\n",
    "\n",
    "sent_length=10\n",
    "x_train_enc_padded = pad_sequences(x_train_enc,padding='pre',maxlen=sent_length)\n",
    "\n",
    "x_test_enc_padded = pad_sequences(x_test_enc,padding='pre',maxlen=sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14628, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_enc_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    keras.layers.Dense(512, activation = \"sigmoid\", input_shape=(10, )),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1),\n",
    "    ])\n",
    "    model.compile(optimizer = \"adam\", loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 512)               5632      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6145 (24.00 KB)\n",
      "Trainable params: 6145 (24.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/checkpoints\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "450/458 [============================>.] - ETA: 0s - loss: 0.4925 - binary_accuracy: 0.7483\n",
      "Epoch 1: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4919 - binary_accuracy: 0.7482 - val_loss: 0.4460 - val_binary_accuracy: 0.7763\n",
      "Epoch 2/20\n",
      "443/458 [============================>.] - ETA: 0s - loss: 0.4605 - binary_accuracy: 0.7682\n",
      "Epoch 2: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4597 - binary_accuracy: 0.7691 - val_loss: 0.4409 - val_binary_accuracy: 0.7796\n",
      "Epoch 3/20\n",
      "442/458 [===========================>..] - ETA: 0s - loss: 0.4563 - binary_accuracy: 0.7693\n",
      "Epoch 3: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4566 - binary_accuracy: 0.7689 - val_loss: 0.4436 - val_binary_accuracy: 0.8023\n",
      "Epoch 4/20\n",
      "410/458 [=========================>....] - ETA: 0s - loss: 0.4485 - binary_accuracy: 0.7770\n",
      "Epoch 4: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4518 - binary_accuracy: 0.7750 - val_loss: 0.4390 - val_binary_accuracy: 0.7468\n",
      "Epoch 5/20\n",
      "448/458 [============================>.] - ETA: 0s - loss: 0.4420 - binary_accuracy: 0.7813\n",
      "Epoch 5: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4427 - binary_accuracy: 0.7808 - val_loss: 0.4320 - val_binary_accuracy: 0.7818\n",
      "Epoch 6/20\n",
      "423/458 [==========================>...] - ETA: 0s - loss: 0.4535 - binary_accuracy: 0.7776\n",
      "Epoch 6: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4527 - binary_accuracy: 0.7778 - val_loss: 0.4305 - val_binary_accuracy: 0.7670\n",
      "Epoch 7/20\n",
      "454/458 [============================>.] - ETA: 0s - loss: 0.4462 - binary_accuracy: 0.7772\n",
      "Epoch 7: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4462 - binary_accuracy: 0.7770 - val_loss: 0.4305 - val_binary_accuracy: 0.7935\n",
      "Epoch 8/20\n",
      "455/458 [============================>.] - ETA: 0s - loss: 0.4464 - binary_accuracy: 0.7786\n",
      "Epoch 8: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4463 - binary_accuracy: 0.7788 - val_loss: 0.4260 - val_binary_accuracy: 0.8018\n",
      "Epoch 9/20\n",
      "406/458 [=========================>....] - ETA: 0s - loss: 0.4382 - binary_accuracy: 0.7911\n",
      "Epoch 9: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4417 - binary_accuracy: 0.7886 - val_loss: 0.4386 - val_binary_accuracy: 0.8018\n",
      "Epoch 10/20\n",
      "450/458 [============================>.] - ETA: 0s - loss: 0.4455 - binary_accuracy: 0.7744\n",
      "Epoch 10: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4457 - binary_accuracy: 0.7737 - val_loss: 0.4441 - val_binary_accuracy: 0.8078\n",
      "Epoch 11/20\n",
      "436/458 [===========================>..] - ETA: 0s - loss: 0.4499 - binary_accuracy: 0.7827\n",
      "Epoch 11: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4506 - binary_accuracy: 0.7814 - val_loss: 0.4289 - val_binary_accuracy: 0.7793\n",
      "Epoch 12/20\n",
      "424/458 [==========================>...] - ETA: 0s - loss: 0.4473 - binary_accuracy: 0.7828\n",
      "Epoch 12: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4466 - binary_accuracy: 0.7842 - val_loss: 0.4266 - val_binary_accuracy: 0.7897\n",
      "Epoch 13/20\n",
      "445/458 [============================>.] - ETA: 0s - loss: 0.4449 - binary_accuracy: 0.7815\n",
      "Epoch 13: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 0s 1ms/step - loss: 0.4455 - binary_accuracy: 0.7810 - val_loss: 0.4266 - val_binary_accuracy: 0.7864\n",
      "Epoch 14/20\n",
      "448/458 [============================>.] - ETA: 0s - loss: 0.4454 - binary_accuracy: 0.7780\n",
      "Epoch 14: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 0s 1ms/step - loss: 0.4446 - binary_accuracy: 0.7791 - val_loss: 0.4266 - val_binary_accuracy: 0.7955\n",
      "Epoch 15/20\n",
      "403/458 [=========================>....] - ETA: 0s - loss: 0.4397 - binary_accuracy: 0.7830\n",
      "Epoch 15: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4404 - binary_accuracy: 0.7831 - val_loss: 0.4229 - val_binary_accuracy: 0.7859\n",
      "Epoch 16/20\n",
      "426/458 [==========================>...] - ETA: 0s - loss: 0.4446 - binary_accuracy: 0.7851\n",
      "Epoch 16: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4457 - binary_accuracy: 0.7839 - val_loss: 0.4263 - val_binary_accuracy: 0.7815\n",
      "Epoch 17/20\n",
      "438/458 [===========================>..] - ETA: 0s - loss: 0.4502 - binary_accuracy: 0.7808\n",
      "Epoch 17: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4516 - binary_accuracy: 0.7801 - val_loss: 0.4232 - val_binary_accuracy: 0.7741\n",
      "Epoch 18/20\n",
      "408/458 [=========================>....] - ETA: 0s - loss: 0.4396 - binary_accuracy: 0.7843\n",
      "Epoch 18: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4378 - binary_accuracy: 0.7850 - val_loss: 0.4243 - val_binary_accuracy: 0.8083\n",
      "Epoch 19/20\n",
      "415/458 [==========================>...] - ETA: 0s - loss: 0.4378 - binary_accuracy: 0.7894\n",
      "Epoch 19: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4377 - binary_accuracy: 0.7888 - val_loss: 0.4213 - val_binary_accuracy: 0.7987\n",
      "Epoch 20/20\n",
      "444/458 [============================>.] - ETA: 0s - loss: 0.4373 - binary_accuracy: 0.7881\n",
      "Epoch 20: saving model to training_1/checkpoints\n",
      "458/458 [==============================] - 1s 1ms/step - loss: 0.4361 - binary_accuracy: 0.7892 - val_loss: 0.4203 - val_binary_accuracy: 0.8015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1784d49d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_enc_padded, y_train, epochs = 20, validation_data=(x_test_enc_padded, y_test), callbacks=[cp_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 - 0s - loss: 0.4203 - binary_accuracy: 0.8015 - 72ms/epoch - 623us/step\n",
      "model, accuracy: 80.15%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test_enc_padded,y_test, verbose=2)\n",
    "print(f\"model, accuracy: {100*acc:5.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoints.data-00000-of-00001', 'checkpoint', 'checkpoints.index']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 0s 605us/step - loss: 1.1936 - binary_accuracy: 0.3768\n",
      "Untrained model, accuracy: 37.68%\n"
     ]
    }
   ],
   "source": [
    "loss_loaded, acc_loaded = model_loaded.evaluate(x_test_enc_padded, y_test)\n",
    "print(f\"Untrained model, accuracy: {100*acc_loaded:5.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x179653e80>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 0s 570us/step - loss: 0.4203 - binary_accuracy: 0.8015\n",
      "Trained model, accuracy: 80.15%\n"
     ]
    }
   ],
   "source": [
    "loss_loaded_trained, acc_loaded_trained = model_loaded.evaluate(x_test_enc_padded, y_test)\n",
    "print(f\"Trained model, accuracy: {100*acc_loaded_trained:5.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
